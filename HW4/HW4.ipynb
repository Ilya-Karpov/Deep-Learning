{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab6a7be",
   "metadata": {},
   "source": [
    "Возьмите датасет www.kaggle.com...ta/kernels\n",
    "\n",
    "1. Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)  \n",
    "2. Обучите на нем модели ResNet 18 и VGG 16 с использованием Fine-tuning (5-10 эпох)  \n",
    "3. Добавьте аугментацию данных к пункту 2  \n",
    "\n",
    "Сравните качество всех 3 полученных подходов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3f523",
   "metadata": {},
   "source": [
    "### Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ebd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964d0514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2a27c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb7af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(3),\n",
    "    tv.transforms.Resize((224, 224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833049ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.ImageFolder(\"hymenoptera_data/train\", transform=transoforms)\n",
    "test_dataset = tv.datasets.ImageFolder(\"hymenoptera_data/val\", transform=transoforms)\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cd87f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0, 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e463c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
    "    net.to(device)\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
    "        print('-' * 20)\n",
    "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
    "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9eee57",
   "metadata": {},
   "source": [
    "#### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a3f098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\DS\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = tv.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c176e9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1aae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(in_features=512, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0bbdacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 1.5944, train acc 0.275, test acc 0.458, time 6.0 sec\n",
      "--------------------\n",
      "epoch 2, loss 4.5155, train acc 0.980, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 3, loss 16.7849, train acc 0.496, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 4, loss 3.4331, train acc 0.020, test acc 0.458, time 3.4 sec\n",
      "--------------------\n",
      "epoch 5, loss 1.0391, train acc 0.504, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.7186, train acc 0.234, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.7424, train acc 0.496, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.7128, train acc 0.496, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.7094, train acc 0.496, test acc 0.542, time 3.4 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.7049, train acc 0.496, test acc 0.542, time 3.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "trainer = torch.optim.Adam(resnet.parameters(), lr=lr)\n",
    "train(resnet, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d05fc4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804df1be",
   "metadata": {},
   "source": [
    "#### VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a974ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tv.models.vgg16(pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbbd568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58c391c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier[6] = nn.Linear(in_features=4096, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a5db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 3.8541, train acc 0.357, test acc 0.542, time 17.2 sec\n",
      "--------------------\n",
      "epoch 2, loss 0.7137, train acc 0.020, test acc 0.458, time 14.9 sec\n",
      "--------------------\n",
      "epoch 3, loss 0.6941, train acc 0.504, test acc 0.458, time 15.1 sec\n",
      "--------------------\n",
      "epoch 4, loss 0.6938, train acc 0.504, test acc 0.458, time 15.1 sec\n",
      "--------------------\n",
      "epoch 5, loss 0.6937, train acc 0.504, test acc 0.458, time 15.6 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.6937, train acc 0.504, test acc 0.458, time 15.7 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.6937, train acc 0.504, test acc 0.458, time 15.9 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.6937, train acc 0.504, test acc 0.458, time 15.2 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.6937, train acc 0.504, test acc 0.458, time 15.3 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.6937, train acc 0.504, test acc 0.458, time 14.6 sec\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(vgg.parameters(), lr=lr)\n",
    "train(vgg, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b3d9c",
   "metadata": {},
   "source": [
    "### Обучите на нем модели ResNet 18 и VGG 16 с использованием Fine-tuning (5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe543686",
   "metadata": {},
   "source": [
    "#### ResNet 18 Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb85973",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_train = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da530bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet_train.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a5f82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_train.fc = nn.Linear(in_features=512, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3449f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in resnet_train.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0920fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 1.1209, train acc 0.238, test acc 0.477, time 2.8 sec\n",
      "--------------------\n",
      "epoch 2, loss 0.6624, train acc 0.566, test acc 0.634, time 2.8 sec\n",
      "--------------------\n",
      "epoch 3, loss 0.4331, train acc 0.836, test acc 0.739, time 3.1 sec\n",
      "--------------------\n",
      "epoch 4, loss 0.4852, train acc 0.779, test acc 0.712, time 3.0 sec\n",
      "--------------------\n",
      "epoch 5, loss 0.5519, train acc 0.697, test acc 0.725, time 2.8 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.5264, train acc 0.758, test acc 0.791, time 2.8 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.4867, train acc 0.816, test acc 0.797, time 2.9 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.4570, train acc 0.811, test acc 0.797, time 2.8 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.4230, train acc 0.836, test acc 0.804, time 2.7 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.3966, train acc 0.869, test acc 0.824, time 2.8 sec\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=lr)\n",
    "train(resnet_train, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360ae00",
   "metadata": {},
   "source": [
    "#### VGG 16 Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07ac4f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\cefeu/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eca6717c60483ba4f20bdd7d732afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg_train = tv.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "799f97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg_train.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c62d5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train.classifier[6] = nn.Linear(in_features=4096, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83dd4e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in vgg_train.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dacd38a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 1.7638, train acc 0.357, test acc 0.458, time 3.9 sec\n",
      "--------------------\n",
      "epoch 2, loss 0.4782, train acc 0.721, test acc 0.856, time 3.9 sec\n",
      "--------------------\n",
      "epoch 3, loss 0.4605, train acc 0.762, test acc 0.712, time 4.0 sec\n",
      "--------------------\n",
      "epoch 4, loss 0.5529, train acc 0.680, test acc 0.863, time 4.0 sec\n",
      "--------------------\n",
      "epoch 5, loss 0.4169, train acc 0.828, test acc 0.843, time 4.0 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.3487, train acc 0.861, test acc 0.771, time 4.0 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.3092, train acc 0.873, test acc 0.804, time 4.0 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.2589, train acc 0.914, test acc 0.843, time 4.0 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.2326, train acc 0.922, test acc 0.863, time 4.1 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.2307, train acc 0.922, test acc 0.869, time 4.1 sec\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=lr)\n",
    "train(vgg_train, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b7a40",
   "metadata": {},
   "source": [
    "### Добавьте аугментацию данных к пункту 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814045e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3499d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(size=(255, 255), ),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e84df94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.ImageFolder(\"hymenoptera_data/train\", transform=transformations)\n",
    "test_dataset = tv.datasets.ImageFolder(\"hymenoptera_data/val\", transform=transformations)\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca4e10",
   "metadata": {},
   "source": [
    "#### VGG 16 с аугментацией данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b1f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_aug = tv.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20823448",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg_aug.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cd8a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_aug.classifier[6] = nn.Linear(in_features=4096, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db5a567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in vgg_aug.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbc82229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 1.8622, train acc 0.365, test acc 0.458, time 3.8 sec\n",
      "--------------------\n",
      "epoch 2, loss 0.3728, train acc 0.852, test acc 0.824, time 3.9 sec\n",
      "--------------------\n",
      "epoch 3, loss 0.4239, train acc 0.746, test acc 0.771, time 3.9 sec\n",
      "--------------------\n",
      "epoch 4, loss 0.4526, train acc 0.746, test acc 0.863, time 3.8 sec\n",
      "--------------------\n",
      "epoch 5, loss 0.3146, train acc 0.861, test acc 0.922, time 3.8 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.2582, train acc 0.889, test acc 0.882, time 3.8 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.2470, train acc 0.910, test acc 0.882, time 4.1 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.1967, train acc 0.934, test acc 0.889, time 3.8 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.1634, train acc 0.939, test acc 0.915, time 3.9 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.1615, train acc 0.934, test acc 0.941, time 4.0 sec\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
    "train(vgg_aug, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa0f64",
   "metadata": {},
   "source": [
    "#### ResNet 18 с аугментацией данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab885ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS\\anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet_aug = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aae72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet_aug.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b4f3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_aug.fc = nn.Linear(in_features=512, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9060ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name, param in resnet_aug.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712ae0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch 1, loss 1.1766, train acc 0.373, test acc 0.464, time 2.9 sec\n",
      "--------------------\n",
      "epoch 2, loss 0.7307, train acc 0.553, test acc 0.529, time 2.7 sec\n",
      "--------------------\n",
      "epoch 3, loss 0.6542, train acc 0.627, test acc 0.562, time 2.8 sec\n",
      "--------------------\n",
      "epoch 4, loss 0.6854, train acc 0.545, test acc 0.608, time 2.7 sec\n",
      "--------------------\n",
      "epoch 5, loss 0.6921, train acc 0.500, test acc 0.641, time 2.8 sec\n",
      "--------------------\n",
      "epoch 6, loss 0.6672, train acc 0.545, test acc 0.686, time 2.7 sec\n",
      "--------------------\n",
      "epoch 7, loss 0.5958, train acc 0.730, test acc 0.745, time 2.7 sec\n",
      "--------------------\n",
      "epoch 8, loss 0.5197, train acc 0.762, test acc 0.810, time 2.6 sec\n",
      "--------------------\n",
      "epoch 9, loss 0.5041, train acc 0.816, test acc 0.817, time 2.7 sec\n",
      "--------------------\n",
      "epoch 10, loss 0.4901, train acc 0.824, test acc 0.824, time 2.9 sec\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
    "train(resnet_aug, train_iter, test_iter, trainer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b96c2",
   "metadata": {},
   "source": [
    "#### Наилучшим, из трех подходов, качеством обладает модель предобученной VGG 16 c аугментацией данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
